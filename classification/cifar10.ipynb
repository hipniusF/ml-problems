{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3439c4ab",
   "metadata": {},
   "source": [
    "# CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57210392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "%matplotlib widget\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e77f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(\n",
    "    root='./dataset',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_dataset = CIFAR10(\n",
    "    root='./dataset',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8d9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bdc760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 128, 3, bias=False),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.Conv2d(512, 512, 3),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 64, 3),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        self.hidden_ly = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "#             nn.Linear(512, 512),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.hidden_ly(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b1e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BobNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BobNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 32, 5, padding=2, bias=False),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.Conv2d(512, 512, 3),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        self.hidden_ly = nn.Sequential(\n",
    "            nn.Linear(288, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.hidden_ly(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2c6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BobNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BobNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 32, 4, padding=0, bias=False),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(32, 32, 4, padding=0),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        self.hidden_ly = nn.Sequential(\n",
    "            nn.Linear(128, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.hidden_ly(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f6c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(model, dt):\n",
    "    X, y = dt\n",
    "    X, y = X.to(device), y.to(device)  \n",
    "    y_pred = model(X)\n",
    "    y_hat = torch.argmax(y_pred, dim=1)\n",
    "    \n",
    "    wrng_p = torch.count_nonzero(y - y_hat) / len(y)\n",
    "    return 1 - wrng_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6eafeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dt, optim, loss_fn, test=False):\n",
    "    X, y = dt\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    y_hat = model(X)\n",
    "\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    if not test:\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "            \n",
    "    return loss.item(), calc_acc(model, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d81c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dtld, optim, loss_fn, test=False):\n",
    "    epoch_losses = []\n",
    "    epoch_acc = []\n",
    "\n",
    "    for batch, dt in enumerate(dtld):\n",
    "        bt_loss, bt_acc = train_step(model, dt, optim, loss_fn, test=test)\n",
    "        epoch_losses.append(bt_loss)\n",
    "        epoch_acc.append(bt_acc)\n",
    "        \n",
    "    return np.array(epoch_losses).mean(), torch.tensor(epoch_acc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15519f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d004823b9e462b883ec656147ce3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1b51ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd83d2f286414064911e350ac072dd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 // TrAcc=0.27471208572387695 // TsAcc=0.34375\n",
      "Epoch 1/100 // TrAcc=0.37098127603530884 // TsAcc=0.38448482751846313\n",
      "Epoch 2/100 // TrAcc=0.41478726267814636 // TsAcc=0.43320685625076294\n",
      "Epoch 3/100 // TrAcc=0.44713690876960754 // TsAcc=0.45736822485923767\n",
      "Epoch 4/100 // TrAcc=0.4693298041820526 // TsAcc=0.4715455174446106\n",
      "Epoch 5/100 // TrAcc=0.4855446219444275 // TsAcc=0.48742014169692993\n",
      "Epoch 6/100 // TrAcc=0.5065978765487671 // TsAcc=0.5095846652984619\n",
      "Epoch 7/100 // TrAcc=0.5226127505302429 // TsAcc=0.5125798583030701\n",
      "Epoch 8/100 // TrAcc=0.537447988986969 // TsAcc=0.5300519466400146\n",
      "Epoch 9/100 // TrAcc=0.5515635013580322 // TsAcc=0.5384384989738464\n",
      "Epoch 10/100 // TrAcc=0.5653191208839417 // TsAcc=0.5471246242523193\n",
      "Epoch 11/100 // TrAcc=0.5729566812515259 // TsAcc=0.5537140369415283\n",
      "Epoch 12/100 // TrAcc=0.5841130614280701 // TsAcc=0.5574081540107727\n",
      "Epoch 13/100 // TrAcc=0.5928102731704712 // TsAcc=0.5654951930046082\n",
      "Epoch 14/100 // TrAcc=0.6009677052497864 // TsAcc=0.577276349067688\n",
      "Epoch 15/100 // TrAcc=0.6077654957771301 // TsAcc=0.5831669569015503\n",
      "Epoch 16/100 // TrAcc=0.6160628795623779 // TsAcc=0.5844648480415344\n",
      "Epoch 17/100 // TrAcc=0.6248400807380676 // TsAcc=0.5850638747215271\n",
      "Epoch 18/100 // TrAcc=0.6296585202217102 // TsAcc=0.5951477885246277\n",
      "Epoch 19/100 // TrAcc=0.6350767612457275 // TsAcc=0.6015375256538391\n",
      "Epoch 20/100 // TrAcc=0.6378158926963806 // TsAcc=0.5979433059692383\n",
      "Epoch 21/100 // TrAcc=0.6430342197418213 // TsAcc=0.6000399589538574\n",
      "Epoch 22/100 // TrAcc=0.6484724879264832 // TsAcc=0.600239634513855\n",
      "Epoch 23/100 // TrAcc=0.6536508202552795 // TsAcc=0.6107228398323059\n",
      "Epoch 24/100 // TrAcc=0.657709538936615 // TsAcc=0.6171126365661621\n",
      "Epoch 25/100 // TrAcc=0.6629278659820557 // TsAcc=0.6149161458015442\n",
      "Epoch 26/100 // TrAcc=0.6666666865348816 // TsAcc=0.6137180328369141\n",
      "Epoch 27/100 // TrAcc=0.6709052920341492 // TsAcc=0.6221046447753906\n",
      "Epoch 28/100 // TrAcc=0.6751639246940613 // TsAcc=0.6236022114753723\n",
      "Epoch 29/100 // TrAcc=0.6784428954124451 // TsAcc=0.6252995133399963\n",
      "Epoch 30/100 // TrAcc=0.6814818978309631 // TsAcc=0.6230031847953796\n",
      "Epoch 31/100 // TrAcc=0.6835412383079529 // TsAcc=0.6324880123138428\n",
      "Epoch 32/100 // TrAcc=0.6881797909736633 // TsAcc=0.6310902833938599\n",
      "Epoch 33/100 // TrAcc=0.689899206161499 // TsAcc=0.6341853141784668\n",
      "Epoch 34/100 // TrAcc=0.6935380697250366 // TsAcc=0.6336861252784729\n",
      "Epoch 35/100 // TrAcc=0.6970169544219971 // TsAcc=0.6370806694030762\n",
      "Epoch 36/100 // TrAcc=0.6999160051345825 // TsAcc=0.637180507183075\n",
      "Epoch 37/100 // TrAcc=0.7022552490234375 // TsAcc=0.6367811560630798\n",
      "Epoch 38/100 // TrAcc=0.7050743699073792 // TsAcc=0.6358826160430908\n",
      "Epoch 39/100 // TrAcc=0.7064139246940613 // TsAcc=0.6404752135276794\n",
      "Epoch 40/100 // TrAcc=0.706313967704773 // TsAcc=0.644069492816925\n",
      "Epoch 41/100 // TrAcc=0.712791919708252 // TsAcc=0.644069492816925\n",
      "Epoch 42/100 // TrAcc=0.7136716246604919 // TsAcc=0.6443690061569214\n",
      "Epoch 43/100 // TrAcc=0.7140914797782898 // TsAcc=0.6480631232261658\n",
      "Epoch 44/100 // TrAcc=0.7170305252075195 // TsAcc=0.6416733264923096\n",
      "Epoch 45/100 // TrAcc=0.7207093834877014 // TsAcc=0.6460663080215454\n",
      "Epoch 46/100 // TrAcc=0.7218090295791626 // TsAcc=0.6466653347015381\n",
      "Epoch 47/100 // TrAcc=0.7230486273765564 // TsAcc=0.6459664702415466\n",
      "Epoch 48/100 // TrAcc=0.7249080538749695 // TsAcc=0.6507588028907776\n",
      "Epoch 49/100 // TrAcc=0.7297864556312561 // TsAcc=0.6522563695907593\n",
      "Epoch 50/100 // TrAcc=0.7304462790489197 // TsAcc=0.6518570184707642\n",
      "Epoch 51/100 // TrAcc=0.7316258549690247 // TsAcc=0.6558506488800049\n",
      "Epoch 52/100 // TrAcc=0.7316258549690247 // TsAcc=0.651457667350769\n",
      "Epoch 53/100 // TrAcc=0.7360844612121582 // TsAcc=0.6544528603553772\n",
      "Epoch 54/100 // TrAcc=0.737324059009552 // TsAcc=0.6530551314353943\n",
      "Epoch 55/100 // TrAcc=0.7389635443687439 // TsAcc=0.6584464907646179\n",
      "Epoch 56/100 // TrAcc=0.7420825362205505 // TsAcc=0.6595447063446045\n",
      "Epoch 57/100 // TrAcc=0.7444817423820496 // TsAcc=0.6602436304092407\n",
      "Epoch 58/100 // TrAcc=0.7448416352272034 // TsAcc=0.657148540019989\n",
      "Epoch 59/100 // TrAcc=0.747600793838501 // TsAcc=0.6601437926292419\n",
      "Epoch 60/100 // TrAcc=0.7476207613945007 // TsAcc=0.6529552936553955\n",
      "Epoch 61/100 // TrAcc=0.7498000860214233 // TsAcc=0.6612420082092285\n",
      "Epoch 62/100 // TrAcc=0.751399576663971 // TsAcc=0.6508586406707764\n",
      "Epoch 63/100 // TrAcc=0.7532789707183838 // TsAcc=0.6537539958953857\n",
      "Epoch 64/100 // TrAcc=0.7541186809539795 // TsAcc=0.6607428193092346\n",
      "Epoch 65/100 // TrAcc=0.7538787722587585 // TsAcc=0.6646365523338318\n",
      "Epoch 66/100 // TrAcc=0.7552782893180847 // TsAcc=0.6598442196846008\n",
      "Epoch 67/100 // TrAcc=0.7580574154853821 // TsAcc=0.6586461663246155\n",
      "Epoch 68/100 // TrAcc=0.7578175067901611 // TsAcc=0.66194087266922\n",
      "Epoch 69/100 // TrAcc=0.7606166005134583 // TsAcc=0.6651358008384705\n",
      "Epoch 70/100 // TrAcc=0.7616562843322754 // TsAcc=0.6643370389938354\n",
      "Epoch 71/100 // TrAcc=0.7630957961082458 // TsAcc=0.6688298583030701\n",
      "Epoch 72/100 // TrAcc=0.7633957266807556 // TsAcc=0.6646365523338318\n",
      "Epoch 73/100 // TrAcc=0.7644553780555725 // TsAcc=0.6677316427230835\n",
      "Epoch 74/100 // TrAcc=0.766814649105072 // TsAcc=0.6642372012138367\n",
      "Epoch 75/100 // TrAcc=0.7689939141273499 // TsAcc=0.6615415215492249\n",
      "Epoch 76/100 // TrAcc=0.7682941555976868 // TsAcc=0.6650359630584717\n",
      "Epoch 77/100 // TrAcc=0.771253228187561 // TsAcc=0.6692292094230652\n",
      "Epoch 78/100 // TrAcc=0.7732925415039062 // TsAcc=0.6618410348892212\n",
      "Epoch 79/100 // TrAcc=0.7737923860549927 // TsAcc=0.667931318283081\n",
      "Epoch 80/100 // TrAcc=0.7745521664619446 // TsAcc=0.6668330430984497\n",
      "Epoch 81/100 // TrAcc=0.7764315605163574 // TsAcc=0.663638174533844\n",
      "Epoch 82/100 // TrAcc=0.7778910994529724 // TsAcc=0.6654353141784668\n",
      "Epoch 83/100 // TrAcc=0.7777910828590393 // TsAcc=0.6719249486923218\n",
      "Epoch 84/100 // TrAcc=0.7784308791160583 // TsAcc=0.6675319671630859\n",
      "Epoch 85/100 // TrAcc=0.7793905735015869 // TsAcc=0.6669328808784485\n",
      "Epoch 86/100 // TrAcc=0.7808701395988464 // TsAcc=0.6718250513076782\n",
      "Epoch 87/100 // TrAcc=0.7821497321128845 // TsAcc=0.6642372012138367\n",
      "Epoch 88/100 // TrAcc=0.7816298604011536 // TsAcc=0.6728234887123108\n",
      "Epoch 89/100 // TrAcc=0.7852087616920471 // TsAcc=0.6654353141784668\n",
      "Epoch 90/100 // TrAcc=0.784468948841095 // TsAcc=0.6687300205230713\n",
      "Epoch 91/100 // TrAcc=0.7857485413551331 // TsAcc=0.663638174533844\n",
      "Epoch 92/100 // TrAcc=0.7843289971351624 // TsAcc=0.6669328808784485\n",
      "Epoch 93/100 // TrAcc=0.7879678606987 // TsAcc=0.6648362874984741\n",
      "Epoch 94/100 // TrAcc=0.7882877588272095 // TsAcc=0.672723650932312\n",
      "Epoch 95/100 // TrAcc=0.7900871634483337 // TsAcc=0.675319492816925\n",
      "Epoch 96/100 // TrAcc=0.7907669544219971 // TsAcc=0.6694288849830627\n",
      "Epoch 97/100 // TrAcc=0.7896073460578918 // TsAcc=0.6720247864723206\n",
      "Epoch 98/100 // TrAcc=0.7923464775085449 // TsAcc=0.6595447063446045\n",
      "Epoch 99/100 // TrAcc=0.7920265793800354 // TsAcc=0.6723242998123169\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "lr=1e-4\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "tr_dtld = DataLoader(train_dataset, batch_size=batch_size)\n",
    "ts_dtld = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "tr_losses = []\n",
    "ts_losses = []\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in (t := trange(epochs)):\n",
    "    ax.clear()\n",
    "        \n",
    "    tr_loss, tr_acc = train_epoch(model, tr_dtld, optim, loss_fn)\n",
    "    ts_loss, ts_acc = train_epoch(model, ts_dtld, optim, loss_fn, test=True)\n",
    "    \n",
    "    tr_losses.append(tr_loss)\n",
    "    ts_losses.append(ts_loss)\n",
    "    \n",
    "    t.write(f'Epoch {epoch}/{epochs} // TrAcc={tr_acc} // TsAcc={ts_acc}')\n",
    "    t.set_description(f'Loss {ts_loss} / Acc {ts_acc}')\n",
    "    \n",
    "    ax.plot(range(epoch+1), tr_losses, label='Train losses')\n",
    "    ax.plot(range(epoch+1), ts_losses, label='Test losses')\n",
    "    ax.set_title(f'BS={batch_size} / lr={lr} \\n\\n Ts_acc={ts_acc}')\n",
    "    ax.legend()\n",
    "    fig.canvas.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

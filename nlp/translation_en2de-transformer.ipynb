{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9048c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext import data, datasets\n",
    "import spacy\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34ac724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Multi30KEn2DeDatasetTokenizer\n",
    "dataset = Multi30KEn2DeDatasetTokenizer(dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673286f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': torch.Size([128, 24]),\n",
       " 'trg': torch.Size([128, 22]),\n",
       " 'src_mask': torch.Size([128, 1, 1, 24]),\n",
       " 'trg_mask': torch.Size([128, 1, 22, 22]),\n",
       " 'trg_y': torch.Size([128, 22])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(\n",
    "    dataset.train,\n",
    "    shuffle=True,\n",
    "    batch_size=128,\n",
    "    collate_fn=dataset.collate_fn)\n",
    "example =  next(iter(dl))\n",
    "{a: example[a].shape for a in example}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f232262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  No checkpoints in ./chkpnts\n"
     ]
    }
   ],
   "source": [
    "from transformers.model import EncoderDecoder, Trainer\n",
    "import os\n",
    "\n",
    "def get_trainer():\n",
    "    model = EncoderDecoder(\n",
    "        len(dataset.src_vocab),\n",
    "        len(dataset.trg_vocab)).to(dev)\n",
    "\n",
    "    trainer = Trainer(model, dataset, criterion='label_smoothing')\n",
    "    try:\n",
    "        chks = os.listdir('./chkpnts')\n",
    "        ns = [int(chk.split('checkpnt_step-')[1].split('k.pt')[0])\n",
    "             for chk in chks]\n",
    "        if len(ns) == 0:\n",
    "            raise Exception('No checkpoints in ./chkpnts')\n",
    "        n = sorted(ns)[-1]\n",
    "        print(f'checkpnt_epoch-{n}k.pt')\n",
    "        trainer.load(f'chkpnts/checkpnt_step-{n}k.pt')\n",
    "\n",
    "    except Exception as e:\n",
    "        print('error: ', e)\n",
    "    return trainer, model\n",
    "\n",
    "trainer, model = get_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595951e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010365486145019531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 59,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72135eef1c444b5bd5976d5ba085dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train_loop(1_000_000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99938f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d32f7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_dl = DataLoader(\n",
    "    dataset.train, shuffle=True, batch_size=1, collate_fn=dataset.collate_fn)\n",
    "example =  next(iter(test_dl))\n",
    "{a: example[a].shape for a in example}\n",
    "\n",
    "src = example['src']\n",
    "tgt = example['trg']\n",
    "src_mask = example['src_mask']\n",
    "tgt_mask = example['trg_mask']\n",
    "trg_y = example['trg_y']\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tgt = model.tgt_embed(tgt)\n",
    "ys = torch.zeros(1, 1).fill_(dataset.start_symbol).type_as(src.data)\n",
    "memory = model.encode(src, src_mask)\n",
    "\n",
    "for _ in range(10):\n",
    "    out = model.decode(\n",
    "        ys, dataset.subsequent_mask(ys.size(1)).type_as(src.data).to(dev), memory, src_mask\n",
    "        )\n",
    "\n",
    "    prob = model.generator(out[:, -1])\n",
    "\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    ys = torch.cat(\n",
    "                [ys, next_word.unsqueeze(0)],\n",
    "        dim=1\n",
    "    )\n",
    "\n",
    "dataset.itos(src[0], field='src'), dataset.itos(ys[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

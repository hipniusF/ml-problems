{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9048c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext import data, datasets\n",
    "import spacy\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afa4b9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenize_en = data.get_tokenizer(\"spacy\", language='en_core_web_sm')\n",
    "tokenize_de = data.get_tokenizer(\"spacy\", language='de_core_news_sm')\n",
    "\n",
    "src = data.Field(tokenize_en)\n",
    "tgt = data.Field(tokenize_de)\n",
    "\n",
    "train, val, test = datasets.Multi30k.splits(\n",
    "    ('.en', '.de'), fields=(src, tgt) , root='./downloads')\n",
    "\n",
    "src_list, trg_list = [], []\n",
    "for dt_pnt in train:\n",
    "    src_list.append(dt_pnt.src)\n",
    "    trg_list.append(dt_pnt.trg)\n",
    "\n",
    "specials = ['<pad>', '<s>', '</s>', \"<blank>\", \"<unk>\"]\n",
    "train.fields['src'].build_vocab(src_list, specials=specials)\n",
    "train.fields['trg'].build_vocab(trg_list, specials=specials)\n",
    "\n",
    "def itos(t, field='trg'):\n",
    "    s = []\n",
    "    for c in t:\n",
    "        s.append(train.fields[field].vocab.itos[c])\n",
    "    return ' '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c2c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673286f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': torch.Size([128, 26]),\n",
       " 'trg': torch.Size([128, 24]),\n",
       " 'src_mask': torch.Size([128, 1, 1, 26]),\n",
       " 'trg_mask': torch.Size([128, 1, 24, 24]),\n",
       " 'trg_y': torch.Size([128, 24])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    src_list, trg_list = [], []\n",
    "    for dt_pnt in batch:\n",
    "        src_list.append(['<s>'] + dt_pnt.src + ['</s>'])\n",
    "        trg_list.append(['<s>'] + dt_pnt.trg + ['</s>'])\n",
    "\n",
    "    src_list = train.fields['src'].pad(src_list)\n",
    "    trg_list = train.fields['trg'].pad(trg_list)\n",
    "    \n",
    "    src_list = train.fields['src'].numericalize(src_list).T.to(dev)\n",
    "    trg_list = train.fields['trg'].numericalize(trg_list).T.to(dev)\n",
    "    trg = trg_list[:, :-1]\n",
    "    trg_y = trg_list[:,1:]\n",
    "\n",
    "    pad = int(train.fields['trg'].numericalize([['<pad>']]))\n",
    "    src_mask = (src_list != pad).unsqueeze(-2).unsqueeze(-3)\n",
    "    trg_mask = (trg != pad).unsqueeze(-2).unsqueeze(-2)\n",
    "\n",
    "    trg_mask = trg_mask & subsequent_mask(\n",
    "        trg.size(-1)).type_as(trg_mask.data)\n",
    "        \n",
    "    return {'src': src_list,\n",
    "            'trg': trg,\n",
    "            'src_mask': src_mask.to(dev),\n",
    "            'trg_mask': trg_mask.to(dev),\n",
    "            'trg_y': trg_y}\n",
    "\n",
    "\n",
    "dl = DataLoader(\n",
    "    train, shuffle=True, batch_size=128, collate_fn=collate_fn)\n",
    "example =  next(iter(dl))\n",
    "{a: example[a].shape for a in example}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f232262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpnt_epoch-0k.pt\n"
     ]
    }
   ],
   "source": [
    "from transformers.model import EncoderDecoder, Trainer\n",
    "import os\n",
    "\n",
    "def get_trainer():\n",
    "    model = EncoderDecoder(\n",
    "        len(train.fields['src'].vocab),\n",
    "        len(train.fields['trg'].vocab)).to(dev)\n",
    "\n",
    "    trainer = Trainer(model)\n",
    "    try:\n",
    "        chks = os.listdir('./chkpnts')\n",
    "        ns = [int(chk.split('checkpnt_step-')[1].split('k.pt')[0])\n",
    "             for chk in chks]\n",
    "        if len(ns) == 0:\n",
    "            raise Exception('No checkpoints in ./chkpnts')\n",
    "        n = sorted(ns)[-1]\n",
    "        print(f'checkpnt_epoch-{n}k.pt')\n",
    "        trainer.load(f'chkpnts/checkpnt_step-{n}k.pt')\n",
    "\n",
    "    except Exception as e:\n",
    "        print('error: ', e)\n",
    "    return trainer, model\n",
    "\n",
    "trainer, model = get_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595951e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010340690612792969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 59,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ee6a8648444b438cca88c8de5279c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train_loop(1_000_000, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d32f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ein Ein Ein <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = example['src']\n",
    "tgt = example['trg']\n",
    "src_mask = example['src_mask']\n",
    "tgt_mask = example['trg_mask']\n",
    "trg_y = example['trg_y']\n",
    "\n",
    "output = model(src, tgt, src_mask, tgt_mask)\n",
    "phrase = torch.argmax(output[0], dim=-1)\n",
    "itos(phrase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

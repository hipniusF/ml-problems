{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9048c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext import data, datasets\n",
    "import spacy\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afa4b9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6869],\n",
       "        [ 898],\n",
       "        [  12],\n",
       "        [1751],\n",
       "        [   1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_en = data.get_tokenizer(\"spacy\", language='en_core_web_sm')\n",
    "tokenize_de = data.get_tokenizer(\"spacy\", language='de_core_news_sm')\n",
    "\n",
    "src = data.Field(tokenize_en)\n",
    "tgt = data.Field(tokenize_de)\n",
    "\n",
    "train, val, test = datasets.Multi30k.splits(\n",
    "    ('.en', '.de'), fields=(src, tgt) , root='./downloads')\n",
    "\n",
    "src_list, trg_list = [], []\n",
    "for dt_pnt in train:\n",
    "    src_list.append(dt_pnt.src)\n",
    "    trg_list.append(dt_pnt.trg)\n",
    "\n",
    "train.fields['src'].build_vocab(src_list)\n",
    "train.fields['trg'].build_vocab(trg_list)\n",
    "train.fields['src'].numericalize([['hello', 'how', 'are', 'you', '<pad>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c2c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673286f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([8, 14]),\n",
       " torch.Size([8, 14]),\n",
       " torch.Size([8, 14, 1, 1]),\n",
       " torch.Size([8, 14, 1, 1]),\n",
       " torch.Size([8, 14])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    src_list, trg_list = [], []\n",
    "    for dt_pnt in batch:\n",
    "        src_list.append(dt_pnt.src)\n",
    "        trg_list.append(['<pad>'] + dt_pnt.trg)\n",
    "\n",
    "    src_list = train.fields['src'].pad(src_list)\n",
    "    trg_list = train.fields['trg'].pad(trg_list)\n",
    "\n",
    "    src_list = train.fields['src'].numericalize(src_list).T.to(dev)\n",
    "    trg_list = train.fields['trg'].numericalize(trg_list).T.to(dev)\n",
    "    trg = trg_list[:, :-1]\n",
    "    trg_y = trg_list[:,1:]\n",
    "\n",
    "    pad = 1\n",
    "    src_mask = (src_list != pad).unsqueeze(-1).unsqueeze(-1)\n",
    "    trg_mask = (trg != pad).unsqueeze(-2)\n",
    "\n",
    "    trg_mask = trg_mask & subsequent_mask(\n",
    "        trg.size(-1)).type_as(trg_mask.data)\n",
    "    \n",
    "    return [src_list,\n",
    "            trg,\n",
    "            src_mask.to(dev),\n",
    "            trg_mask.to(dev)[:,:,0].unsqueeze(-1).unsqueeze(-1),\n",
    "            trg_y]\n",
    "\n",
    "\n",
    "dl = DataLoader(\n",
    "    train, shuffle=False, batch_size=8, collate_fn=collate_fn)\n",
    "example =  next(iter(dl))\n",
    "[a.shape for a in example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181d7d65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.4382e-05, 3.8034e-05, 2.9569e-05,  ..., 2.6254e-05,\n",
       "          3.0642e-05, 3.6709e-05],\n",
       "         [4.2532e-05, 4.2545e-05, 2.8504e-05,  ..., 3.2837e-05,\n",
       "          4.5003e-05, 3.6043e-05],\n",
       "         [3.1261e-05, 3.4890e-05, 3.0717e-05,  ..., 3.6743e-05,\n",
       "          3.4505e-05, 4.2707e-05],\n",
       "         ...,\n",
       "         [3.2411e-05, 3.5660e-05, 3.1765e-05,  ..., 4.4888e-05,\n",
       "          2.8996e-05, 5.5060e-05],\n",
       "         [3.1013e-05, 4.0144e-05, 3.6139e-05,  ..., 3.1309e-05,\n",
       "          2.6182e-05, 5.4794e-05],\n",
       "         [3.1932e-05, 4.1850e-05, 4.1147e-05,  ..., 4.3117e-05,\n",
       "          2.5125e-05, 6.8875e-05]],\n",
       "\n",
       "        [[5.5289e-05, 3.6400e-05, 3.8453e-05,  ..., 3.2903e-05,\n",
       "          3.1037e-05, 4.6313e-05],\n",
       "         [3.5351e-05, 4.3255e-05, 3.1099e-05,  ..., 4.2300e-05,\n",
       "          3.2589e-05, 3.6187e-05],\n",
       "         [4.7280e-05, 3.3941e-05, 3.2998e-05,  ..., 3.6821e-05,\n",
       "          3.3285e-05, 5.4245e-05],\n",
       "         ...,\n",
       "         [3.8535e-05, 4.1556e-05, 3.1715e-05,  ..., 3.9869e-05,\n",
       "          2.9917e-05, 5.0891e-05],\n",
       "         [3.1272e-05, 5.7304e-05, 3.2555e-05,  ..., 3.1024e-05,\n",
       "          2.5742e-05, 6.2904e-05],\n",
       "         [4.1465e-05, 3.7413e-05, 3.7410e-05,  ..., 3.3901e-05,\n",
       "          3.5979e-05, 5.0822e-05]],\n",
       "\n",
       "        [[3.2817e-05, 4.3972e-05, 4.4009e-05,  ..., 3.4471e-05,\n",
       "          2.7552e-05, 3.9217e-05],\n",
       "         [2.9261e-05, 4.7506e-05, 3.4045e-05,  ..., 3.5399e-05,\n",
       "          4.6455e-05, 4.2058e-05],\n",
       "         [2.8935e-05, 3.6017e-05, 4.3400e-05,  ..., 3.9221e-05,\n",
       "          3.0556e-05, 4.9509e-05],\n",
       "         ...,\n",
       "         [3.9162e-05, 5.0037e-05, 4.0689e-05,  ..., 3.0062e-05,\n",
       "          3.1630e-05, 5.5790e-05],\n",
       "         [3.8798e-05, 2.6468e-05, 3.7412e-05,  ..., 3.9060e-05,\n",
       "          3.6702e-05, 5.2022e-05],\n",
       "         [4.1634e-05, 3.9479e-05, 3.3597e-05,  ..., 4.0222e-05,\n",
       "          3.0387e-05, 6.8649e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[4.3046e-05, 3.9855e-05, 3.2081e-05,  ..., 3.8811e-05,\n",
       "          3.3263e-05, 3.5726e-05],\n",
       "         [2.6573e-05, 3.2032e-05, 3.8635e-05,  ..., 3.3513e-05,\n",
       "          3.2637e-05, 4.2182e-05],\n",
       "         [4.0940e-05, 4.6252e-05, 3.3661e-05,  ..., 2.5279e-05,\n",
       "          3.4812e-05, 4.2180e-05],\n",
       "         ...,\n",
       "         [3.2413e-05, 3.6473e-05, 3.7357e-05,  ..., 4.1089e-05,\n",
       "          3.5774e-05, 5.1590e-05],\n",
       "         [3.9911e-05, 4.3756e-05, 3.2831e-05,  ..., 4.5176e-05,\n",
       "          2.7549e-05, 4.3139e-05],\n",
       "         [3.8758e-05, 4.7087e-05, 4.0090e-05,  ..., 4.3067e-05,\n",
       "          3.1632e-05, 7.3813e-05]],\n",
       "\n",
       "        [[3.4214e-05, 4.0201e-05, 5.8238e-05,  ..., 4.3845e-05,\n",
       "          2.6723e-05, 2.9919e-05],\n",
       "         [3.3399e-05, 2.8432e-05, 3.6964e-05,  ..., 3.0929e-05,\n",
       "          3.3039e-05, 3.3334e-05],\n",
       "         [2.9797e-05, 5.1021e-05, 4.2342e-05,  ..., 4.6568e-05,\n",
       "          2.3946e-05, 5.4076e-05],\n",
       "         ...,\n",
       "         [3.9001e-05, 4.7752e-05, 3.1131e-05,  ..., 3.5190e-05,\n",
       "          3.4780e-05, 4.1754e-05],\n",
       "         [4.4017e-05, 3.8183e-05, 3.1284e-05,  ..., 3.0717e-05,\n",
       "          3.1359e-05, 5.4318e-05],\n",
       "         [4.0329e-05, 4.5757e-05, 3.8067e-05,  ..., 3.2858e-05,\n",
       "          3.0920e-05, 4.4710e-05]],\n",
       "\n",
       "        [[3.8155e-05, 3.5297e-05, 4.1743e-05,  ..., 3.6031e-05,\n",
       "          4.5239e-05, 4.0239e-05],\n",
       "         [3.2969e-05, 3.8814e-05, 2.8973e-05,  ..., 3.2819e-05,\n",
       "          3.8100e-05, 3.1018e-05],\n",
       "         [3.1456e-05, 3.9166e-05, 3.5880e-05,  ..., 4.2783e-05,\n",
       "          3.2748e-05, 4.4197e-05],\n",
       "         ...,\n",
       "         [4.5125e-05, 4.4311e-05, 3.9074e-05,  ..., 3.7536e-05,\n",
       "          3.3606e-05, 2.6323e-05],\n",
       "         [5.0774e-05, 3.9512e-05, 4.0058e-05,  ..., 3.3239e-05,\n",
       "          3.2447e-05, 4.1002e-05],\n",
       "         [2.4581e-05, 5.7506e-05, 3.5305e-05,  ..., 3.3918e-05,\n",
       "          4.3263e-05, 5.0395e-05]]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.model import EncoderDecoder\n",
    "\n",
    "model = EncoderDecoder(\n",
    "    len(train.fields['src'].vocab),\n",
    "    len(train.fields['trg'].vocab)).to(dev)\n",
    "model(*example[:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

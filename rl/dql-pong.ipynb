{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c37866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from time import sleep, time\n",
    "from itertools import count\n",
    "from collections import deque, namedtuple\n",
    "from tqdm.notebook import trange, tqdm\n",
    "try:\n",
    "    import gym\n",
    "except ModuleNotFoundError:\n",
    "    !pip install gym\n",
    "    !pip install ale-py\n",
    "    !pip install gym[atari]\n",
    "    !pip install gym[accept-rom-license]\n",
    "    import gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "to_tensor = lambda x: torch.tensor(x, device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a961f3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n",
      "/usr/local/lib/python3.9/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"ALE/Pong-v5\", repeat_action_probability=0)\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97212760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play\n",
    "def play(policy, runs=50, wait=0):\n",
    "    for _ in trange(runs):\n",
    "        state = env.reset()\n",
    "        for _ in count():\n",
    "            state, reward, done, info = env.step(policy(state))\n",
    "            plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "            sleep(wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96c658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.queue = deque([], maxlen=capacity)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "        \n",
    "    def push(self, *args):\n",
    "        self.queue.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batchsize):\n",
    "        return random.sample(self.queue, batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc960e9-aa7a-4b0b-9121-1895b98a38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(net, losses, rewards):\n",
    "    torch.save({\n",
    "        'net': net.state_dict(),\n",
    "        'losses': losses,\n",
    "        'rewards': rewards\n",
    "    }, 'chkpnt.pt')\n",
    "\n",
    "def load():\n",
    "    chkpnt = torch.load('./chkpnt.pt', map_location=torch.device(dev))\n",
    "    return chkpnt['net'], chkpnt['losses'], chkpnt['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918dfbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DQN(nn.Module): # size((210, 160, 3)) -> size(6)\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 8, 4),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 4, 2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.l = nn.Sequential(\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, env.action_space.n)\n",
    "        )\n",
    "        self.flat = nn.Flatten()\n",
    "        self.transformations = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((110, 84)),\n",
    "            transforms.CenterCrop((84, 84))\n",
    "        ])\n",
    "    \n",
    "    def transforms(self, x):\n",
    "        return self.transformations(x).to(dev)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if len(x) < 4:\n",
    "            x = x.unsqueeze(0)\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        return self.l(x)\n",
    "\n",
    "\n",
    "net = DQN().to(dev)\n",
    "target_net = DQN().to(dev)\n",
    "memory = ReplayMemory(25000)\n",
    "losses = []\n",
    "rewards = []\n",
    "try:\n",
    "    state_dict, losses, rewards = load()\n",
    "    net.load_state_dict(state_dict)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "target_net.load_state_dict(net.state_dict())\n",
    "# net(net.transforms(state)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5df7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(memory, net, target_net, criterion, optim):\n",
    "    # Update weights\n",
    "    transition_batch = memory.sample(BS)\n",
    "\n",
    "    states = to_tensor(np.array([(batch[0]) for batch in transition_batch]))\n",
    "    next_states = torch.cat(\n",
    "        [net.transforms(batch[2]).unsqueeze(0) for batch in transition_batch])\n",
    "    future_q = target_net(next_states)\n",
    "    \n",
    "    Y = net(states)\n",
    "    for i, (state, action, next_state, reward, done) in enumerate(transition_batch):\n",
    "        reward = to_tensor(reward)\n",
    "    \n",
    "        y = reward if done else reward + gamma*torch.max(future_q[i])\n",
    "        Y[i][action] = y\n",
    "\n",
    "    for p in net.parameters():\n",
    "        p.grad = None\n",
    "    loss = criterion(Y, net(states))\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48af6ae-2733-4837-b2c8-ac06e566ebb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/2645324160.py:8: RuntimeWarning: Mean of empty slice.\n",
      "  np.array(losses[-100:]).mean()\n",
      "/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches(15, 6, forward=True)\n",
    "\n",
    "axs[0].plot(losses, label='losses')\n",
    "axs[1].plot(rewards, label='rewards')\n",
    "\n",
    "[ax.legend() for ax in axs]\n",
    "np.array(losses[-100:]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a5947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502b1d9321d54bb199ba817b3e36d02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 1000\n",
    "gamma = 0.99\n",
    "BS = 64\n",
    "C = 1000 # update target\n",
    "\n",
    "EPS_START = 1\n",
    "EPS_END = 0.02\n",
    "EPS_DECAY = 0.00002\n",
    "get_eps = lambda steps_done: EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done * EPS_DECAY)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optim = torch.optim.Adam(net.parameters(), lr=5e-5)\n",
    "\n",
    "steps_done = 0\n",
    "target_count = 0\n",
    "for episode in (tr := trange(len(rewards), n_episodes)):\n",
    "    rewards.append(0)\n",
    "    state = net.transforms(env.reset())\n",
    "    for t in count():\n",
    "        eps_threshold = get_eps(steps_done)\n",
    "        steps_done += 1\n",
    "        \n",
    "        if np.random.uniform(0, 1) < eps_threshold:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = torch.argmax(net(state)).item()\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        rewards[episode] += reward\n",
    "        memory.push(state.cpu().numpy(), action, next_state, reward, done)\n",
    "\n",
    "        if len(memory) >= BS:\n",
    "            loss = optimize_model(memory, net, target_net, criterion, optim)\n",
    "            losses.append(loss)\n",
    "            tr.set_description(f'Loss {loss:.4f}, Reward {rewards[-1]:04.1f}, Step {t:04d}')\n",
    "        else:\n",
    "            tr.set_description(f'Reward {rewards[-1]:04.1f}, Step {t:04d}')\n",
    "\n",
    "        state = net.transforms(next_state)\n",
    "        if target_count >= C:\n",
    "            target_net.load_state_dict(net.state_dict())\n",
    "            target_count = 0\n",
    "        else:\n",
    "            target_count += 1\n",
    "        if done:\n",
    "            break\n",
    "    save(net, losses, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bade07c-df2d-409f-a562-56576b341a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1000 * 300\n",
    "plt.plot(range(r), [get_eps(x) for x in range(r)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66d4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches(15, 6, forward=True)\n",
    "\n",
    "axs[0].plot(losses, label='losses')\n",
    "axs[1].plot(rewards, label='rewards')\n",
    "\n",
    "[ax.legend() for ax in axs]\n",
    "np.array(losses[-100:]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state):\n",
    "     return torch.argmax(net(net.transforms(state))).item()\n",
    "play(policy, runs=10, wait=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
